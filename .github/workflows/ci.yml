name: CI

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: pip install -e ".[dev]"

      - name: Run tests
        run: pytest -q

      - name: Run demo-quick pipeline
        run: make demo-quick

      - name: Validate manifest
        run: python scripts/validate_manifest.py outputs/demo_quick/manifest.json

      - name: Verify determinism (run demo twice)
        run: |
          # Determinism check: With fixed NumPy seed and pyvinecopulib seeds,
          # two runs with identical inputs must produce identical numeric outputs.
          # We compare var_es_timeseries.csv which contains all VaR/ES forecasts
          # from Monte Carlo simulation -- the most sensitive artifact to RNG state.

          # Save first run artifacts
          cp outputs/demo_quick/var_es_timeseries.csv /tmp/var_es_run1.csv
          cp outputs/demo_quick/backtest_summary.csv /tmp/backtest_run1.csv

          # Clean and run again
          rm -rf outputs/demo_quick/*
          make demo-quick

          # Compare var_es_timeseries.csv exactly (numeric columns)
          python -c "
          import pandas as pd
          import numpy as np

          df1 = pd.read_csv('/tmp/var_es_run1.csv')
          df2 = pd.read_csv('outputs/demo_quick/var_es_timeseries.csv')

          # Columns must match
          assert list(df1.columns) == list(df2.columns), 'Column mismatch'
          assert len(df1) == len(df2), f'Row count mismatch: {len(df1)} vs {len(df2)}'

          # Compare all numeric columns exactly
          numeric_cols = df1.select_dtypes(include=[np.number]).columns
          for col in numeric_cols:
              # Use array_equal for exact match (handles NaN correctly)
              if not np.array_equal(df1[col].values, df2[col].values, equal_nan=True):
                  diff_idx = np.where(df1[col].values != df2[col].values)[0]
                  raise AssertionError(
                      f'{col}: values differ at {len(diff_idx)} rows. '
                      f'First diff at row {diff_idx[0]}: {df1[col].iloc[diff_idx[0]]} vs {df2[col].iloc[diff_idx[0]]}'
                  )

          # Also verify backtest summary (derived from var_es_timeseries)
          bs1 = pd.read_csv('/tmp/backtest_run1.csv')
          bs2 = pd.read_csv('outputs/demo_quick/backtest_summary.csv')
          for col in ['n_breaches', 'hit_rate', 'kupiec_pvalue', 'chris_pvalue', 'es_ratio']:
              if col in bs1.columns:
                  assert np.allclose(bs1[col], bs2[col], rtol=1e-12, equal_nan=True), f'{col} differs'

          print('Determinism check passed: var_es_timeseries.csv is byte-identical across runs')
          "

      - name: Validate order_source in model cards
        run: |
          python -c "
          import json

          for fname in ['outputs/demo_quick/vine_model_card_static.json',
                        'outputs/demo_quick/vine_model_card_gas.json']:
            card = json.load(open(fname))
            assert card['order_source'] == 'train_only_fixed', \
              f'{fname}: expected train_only_fixed, got {card[\"order_source\"]}'
          print('Order source validation passed: no OOS leakage in structure selection')
          "
